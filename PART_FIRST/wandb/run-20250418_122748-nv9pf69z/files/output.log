Step 1: Setting device
Step 3: Loading datasets
Step 2: Preparing transforms
Cnet(
  (feature_extractor): Sequential(
    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): ReLU()
    (drop1): Dropout(p=0.25, inplace=False)
    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act2): ReLU()
    (drop2): Dropout(p=0.25, inplace=False)
    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act3): ReLU()
    (drop3): Dropout(p=0.25, inplace=False)
    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=50176, out_features=128, bias=True)
    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=128, out_features=10, bias=True)
  )
)
Step 5: Loading model
 12%|███████████▍                                                                                   | 15/125 [00:18<01:57,  1.07s/it]
torch.Size([64, 3, 224, 224])
conv input shape :  torch.Size([64, 3, 224, 224])
torch.Size([64, 3, 224, 224])
conv input shape :  torch.Size([64, 3, 224, 224])
torch.Size([64, 3, 224, 224])
conv input shape :  torch.Size([64, 3, 224, 224])
torch.Size([64, 3, 224, 224])
conv input shape :  torch.Size([64, 3, 224, 224])
torch.Size([64, 3, 224, 224])
conv input shape :  torch.Size([64, 3, 224, 224])
torch.Size([64, 3, 224, 224])
conv input shape :  torch.Size([64, 3, 224, 224])
torch.Size([64, 3, 224, 224])
conv input shape :  torch.Size([64, 3, 224, 224])
torch.Size([64, 3, 224, 224])
conv input shape :  torch.Size([64, 3, 224, 224])
torch.Size([64, 3, 224, 224])
conv input shape :  torch.Size([64, 3, 224, 224])
torch.Size([64, 3, 224, 224])
conv input shape :  torch.Size([64, 3, 224, 224])
torch.Size([64, 3, 224, 224])
conv input shape :  torch.Size([64, 3, 224, 224])
torch.Size([64, 3, 224, 224])
conv input shape :  torch.Size([64, 3, 224, 224])
torch.Size([64, 3, 224, 224])
conv input shape :  torch.Size([64, 3, 224, 224])
torch.Size([64, 3, 224, 224])
conv input shape :  torch.Size([64, 3, 224, 224])
torch.Size([64, 3, 224, 224])
conv input shape :  torch.Size([64, 3, 224, 224])
torch.Size([64, 3, 224, 224])
conv input shape :  torch.Size([64, 3, 224, 224])
torch.Size([64, 3, 224, 224])
conv input shape :  torch.Size([64, 3, 224, 224])
torch.Size([64, 3, 224, 224])
conv input shape :  torch.Size([64, 3, 224, 224])
torch.Size([64, 3, 224, 224])
conv input shape :  torch.Size([64, 3, 224, 224])
torch.Size([64, 3, 224, 224])
conv input shape :  torch.Size([64, 3, 224, 224])
torch.Size([64, 3, 224, 224])
conv input shape :  torch.Size([64, 3, 224, 224])
torch.Size([64, 3, 224, 224])
conv input shape :  torch.Size([64, 3, 224, 224])
torch.Size([64, 3, 224, 224])
conv input shape :  torch.Size([64, 3, 224, 224])
torch.Size([64, 3, 224, 224])
conv input shape :  torch.Size([64, 3, 224, 224])
torch.Size([64, 3, 224, 224])
conv input shape :  torch.Size([64, 3, 224, 224])
 19%|██████████████████▏                                                                            | 24/125 [00:29<02:02,  1.21s/it]

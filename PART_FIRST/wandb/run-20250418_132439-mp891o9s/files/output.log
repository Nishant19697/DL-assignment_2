Cnet(
  (feature_extractor): Sequential(
    (conv1): Conv2d(3, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): ReLU()
    (drop1): Dropout(p=0.25, inplace=False)
    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act2): ReLU()
    (drop2): Dropout(p=0.25, inplace=False)
    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act3): ReLU()
    (drop3): Dropout(p=0.25, inplace=False)
    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act4): ReLU()
    (drop4): Dropout(p=0.25, inplace=False)
    (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (conv5): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (bn5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act5): ReLU()
    (drop5): Dropout(p=0.25, inplace=False)
    (pool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=1024, bias=True)
    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=1024, out_features=10, bias=True)
  )
)
100%|████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:10<00:00,  2.95it/s]
Epoch 1/10 | Train Loss: 2.2209 | Val Loss: 2.3199 | Val Acc: 12.25%
100%|████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:10<00:00,  3.09it/s]
Epoch 2/10 | Train Loss: 2.0262 | Val Loss: 2.3366 | Val Acc: 15.00%
100%|████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:10<00:00,  3.05it/s]
Epoch 3/10 | Train Loss: 1.9409 | Val Loss: 2.2464 | Val Acc: 19.05%
100%|████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:10<00:00,  2.99it/s]
Epoch 4/10 | Train Loss: 1.8882 | Val Loss: 2.4380 | Val Acc: 13.50%
100%|████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:10<00:00,  3.00it/s]
Epoch 5/10 | Train Loss: 1.8194 | Val Loss: 2.5560 | Val Acc: 12.45%
100%|████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:10<00:00,  3.07it/s]
Epoch 6/10 | Train Loss: 1.7723 | Val Loss: 2.6144 | Val Acc: 12.10%
100%|████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:10<00:00,  3.06it/s]
Epoch 7/10 | Train Loss: 1.7297 | Val Loss: 2.7528 | Val Acc: 11.60%
100%|████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:10<00:00,  3.04it/s]
Epoch 8/10 | Train Loss: 1.6766 | Val Loss: 2.7532 | Val Acc: 14.45%
100%|████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:10<00:00,  2.99it/s]
Epoch 9/10 | Train Loss: 1.6225 | Val Loss: 2.7989 | Val Acc: 15.15%
100%|████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:10<00:00,  3.06it/s]
Epoch 10/10 | Train Loss: 1.5648 | Val Loss: 2.9705 | Val Acc: 15.00%
Test Loss: 2.9494 | Test Acc: 15.75%
